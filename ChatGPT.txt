Training
ChatGPT is a member of the generative pre-trained transformer (GPT) class of language models. It is a task-specific GPT that was fine-tuned to target conversational usage, and was originally built upon an improved version of OpenAI's GPT-3 model known as "GPT-3.5".[7]

The fine-tuning process leveraged both supervised learning as well as reinforcement learning in a process called reinforcement learning from human feedback (RLHF).[8][9] Both approaches use human trainers to improve the model's performance. In the case of supervised learning, the model was provided with conversations in which the trainers played both sides: the user and the AI assistant. In the reinforcement learning step, human trainers first ranked responses that the model had created in a previous conversation.[10] These rankings were used to create "reward models" that were used to fine-tune the model further by using several iterations of Proximal Policy Optimization (PPO).[8][11]